{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14299389",
   "metadata": {},
   "source": [
    "Imported the neccessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a1f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re \n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate ,KFold, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b7a26b",
   "metadata": {},
   "source": [
    "Set the stopwords to the stopwords in the english language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88aa6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5e4b9b",
   "metadata": {},
   "source": [
    "Imported the data from a tab separated file containing the different emails marked as spam or ham and instantiated an object from the PorterStemmer library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62f7207",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SMSSpamCollection.tsv',sep='\\t',header=None)\n",
    "data.columns = ['label', 'body_text']\n",
    "pn = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc80a6c",
   "metadata": {},
   "source": [
    "Created a function which will take in the text in the email and remove all punctuation, splits each word and removes whitespace, stems each word and removes all stopwords from the text in each email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc6baee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: list) -> list:\n",
    "    text = ''.join([i for i in text if i not in string.punctuation])\n",
    "    tokenize = re.split('\\W+',string=text)\n",
    "    text = ' '.join([pn.stem(i) for i in tokenize if i not in stopwords])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7103941",
   "metadata": {},
   "source": [
    "Creates new column which applies the function above to the body_text column in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "532cc5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['clean_data'] = data['body_text'].apply(lambda x : clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba6b0ff",
   "metadata": {},
   "source": [
    "Shows the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f82536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>clean_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>ive search right word thank breather i promis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think goe usf live around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>even brother like speak they treat like aid pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>i have a date on sunday with will</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text  \\\n",
       "0   ham  I've been searching for the right words to tha...   \n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3   ham  Even my brother is not like to speak with me. ...   \n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                          clean_data  \n",
       "0  ive search right word thank breather i promis ...  \n",
       "1  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "2        nah i dont think goe usf live around though  \n",
       "3  even brother like speak they treat like aid pa...  \n",
       "4                  i have a date on sunday with will  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d878f18",
   "metadata": {},
   "source": [
    "In this cell two new additional columns are added to the dataset, a column showing the amount of characters in each email is shown and another column showing what percent is punctuation in the body_text column is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa7188a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['body_len'] = data['body_text'].apply(lambda x : len(x) - x.count(' '))\n",
    "\n",
    "def punc(text: list) -> list:\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round((count / (len(text) - text.count(' '))),3) * 100 \n",
    "\n",
    "data['punc_%'] = data['body_text'].apply(lambda x: punc(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0ffa62",
   "metadata": {},
   "source": [
    "The new data set is shown below with the addition of two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a4aa4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>clean_data</th>\n",
       "      <th>body_len</th>\n",
       "      <th>punc_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>ive search right word thank breather i promis ...</td>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think goe usf live around though</td>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>even brother like speak they treat like aid pa...</td>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>i have a date on sunday with will</td>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text  \\\n",
       "0   ham  I've been searching for the right words to tha...   \n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3   ham  Even my brother is not like to speak with me. ...   \n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                          clean_data  body_len  punc_%  \n",
       "0  ive search right word thank breather i promis ...       160     2.5  \n",
       "1  free entri 2 wkli comp win fa cup final tkt 21...       128     4.7  \n",
       "2        nah i dont think goe usf live around though        49     4.1  \n",
       "3  even brother like speak they treat like aid pa...        62     3.2  \n",
       "4                  i have a date on sunday with will        28     7.1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d69300a",
   "metadata": {},
   "source": [
    "A count vectorizer was applied to the clean_data and this section stored in the X_counts variable, was concatenated with the body length and punctuation percentage column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39cd31db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punc_%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>2.5</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>131</td>\n",
       "      <td>6.1</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>29</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>48</td>\n",
       "      <td>14.6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>21</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5568 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      body_len  punc_%   0  1  2  3  4  5  6  7  ...  34  35  36  37  38  39  \\\n",
       "0          160     2.5  15  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "1          128     4.7  22  5  5  5  0  1  3  0  ...   2   1   0   0   0   0   \n",
       "2           49     4.1   7  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "3           62     3.2   7  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "4           28     7.1   1  0  0  0  0  0  0  0  ...   0   1   0   0   0   0   \n",
       "...        ...     ...  .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..   \n",
       "5563       131     6.1  21  5  3  5  0  0  1  0  ...   0   0   1   0   0   0   \n",
       "5564        29     3.4   5  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "5565        48    14.6   3  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "5566       100     1.0  13  0  0  0  0  0  0  0  ...   1   2   0   0   0   0   \n",
       "5567        21     4.8   2  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "\n",
       "      40  41  42  43  \n",
       "0      0   0   0   0  \n",
       "1      0   0   0   0  \n",
       "2      0   0   0   0  \n",
       "3      0   0   0   0  \n",
       "4      0   0   0   0  \n",
       "...   ..  ..  ..  ..  \n",
       "5563   0   0   0   0  \n",
       "5564   0   1   0   0  \n",
       "5565   0   0   0   0  \n",
       "5566   0   0   0   0  \n",
       "5567   0   0   0   0  \n",
       "\n",
       "[5568 rows x 46 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vect = CountVectorizer(analyzer=clean_text)\n",
    "X_counts = tf_vect.fit_transform(data['clean_data'])\n",
    "x = pd.DataFrame(X_counts.toarray())\n",
    "X_features = pd.concat([data['body_len'],data['punc_%'], x],axis=1)\n",
    "X_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0370a91",
   "metadata": {},
   "source": [
    "A Random Forest Classifier model was applied to the features in the X_features column and label(spam vs ham). The \n",
    "classification report is shown below which gives different measurements on how reliable the model is. A grid search was employed in order to optimize the model. Different estimators were tested as well as different values for the depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9161b46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       964\n",
      "        spam       0.94      0.91      0.93       150\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.97      0.95      0.96      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       964\n",
      "        spam       0.98      0.89      0.93       150\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.98      0.94      0.96      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       964\n",
      "        spam       0.98      0.88      0.93       150\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.98      0.94      0.96      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       964\n",
      "        spam       0.96      0.89      0.93       150\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.97      0.94      0.96      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       964\n",
      "        spam       0.97      0.89      0.93       150\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.98      0.94      0.96      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       964\n",
      "        spam       0.97      0.90      0.93       150\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.98      0.95      0.96      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       964\n",
      "        spam       0.97      0.89      0.93       150\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.98      0.94      0.96      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       964\n",
      "        spam       0.97      0.89      0.93       150\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.98      0.94      0.96      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99       964\n",
      "        spam       0.97      0.91      0.94       150\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.98      0.95      0.96      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, data['label'], test_size=0.2)\n",
    "\n",
    "def train_RF(n_est: int,dep: int):\n",
    "    rf_n = RandomForestClassifier(n_estimators=n_est, max_depth=dep,n_jobs=-1)\n",
    "    model = rf_n.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    n = classification_report(y_test,y_pred)\n",
    "    print(n)\n",
    "\n",
    "for n_est in [10,50,100]:\n",
    "    for dep in [10,20,30]:\n",
    "        train_RF(n_est,dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a698933b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba6c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
